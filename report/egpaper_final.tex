\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{Truth or DeGPTion: Evaluating Lie Detection Capabilities of GPT-3.5 through Fine-Tuning on Personal Opinions, Autobiographical Memories, and Intentions}


\author{
Tanner Graves\\
{\tt\small tanneraaron.graves@studenti.unipd.it}
\and
Marco Uderzo\\
{\tt\small marco.uderzo@studenti.unipd.it}
\and
Francesco Vo \\
{\tt\small francesco.vo@studenti.unipd.it}
\and
Mehran Faraji\\
{\tt\small mehran.faraji@studenti.unipd.it}
\and
Claudio Palmeri \\
{\tt\small claudio.palmeri@studenti.unipd.it}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
}

\maketitle
%\thispagestyle{empty}


%%%%%%%%% ABSTRACT
\begin{abstract}
This paper aims at evaluating the capabilities of GPT3.5 in the task of Lie Detection.
This is done through the fine-tuning of GPT3 on three English-language datasets encompassing 
personal opinions, autobiographical memories, and future intentions. 
Fine-tuning of LLMs consists in adapting a pre-trained language model to a specific 
task by further training the model on task-specific data, thereby 
enhancing its ability to generate contextually relevant and coherent text in 
line with the desired task objectives. In our investigation, the objective is to 
discern and classify instances of truth or deception.

\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
Multiple papers consistently show that the capability of humans to discern truth from deception
is at chance level, there is a growing interest in employing Machine Learning methods, especially
based on the Transformer Model, to more accurately predict the truthfullness of a statement.
Indeed, the inherent pattern recognition capability of ML Models allows them to pick up subtle cues
that humans just seem to miss. In this paper, we will use OpenAI's GPT-3.5 Large Language Model (LLM),
performing benchmarks on the performance of the base model, and then on a GPT-3.5 model specifically
fine-tuned on the Opinion Dataset (Deceptive Opinions), Memory Dataset (Hippocorpus) and Intention Dataset.


\section{Methods}

\subsection{Dataset Preprocessing}

(Explain what has been done in the datasets notebook).

\subsection{Experimental Setup: Scenarios}

We first aggregated the three train and test sets from 
Scenario 1 (explain what that is). Then we fine-tuned and tested the model 
on those aggregated sets. This Scenario assesses 
the capacity of the model to learn and generalize from 
samples of truthful and deceptive narratives from multiple 
contexts. 



\subsection{GPT-3.5 Fine-Tuning}
The datasets were formatted into JSON to align with the expected input format 
of the OpenAI API, subsequently divided into training, validation, and test sets. 
To manage the potential high computational costs, the model was trained on a subset of the dataset.
The model was trained utilizing the OpenAI API, and its performance was assessed through 
testing and comparison with GPT-3.5. Further experimentation was conducted to assess 
the impact of engineering the system prompt on overall performance.

Specifically, we noticed that the baseline GPT-3.5 prefers giving verbose or indecisive answers.
Verbose answers, that actually classify a statement as genuine or deceptive can be classified easily.
Nonetheless, the model decides not to give a definitive answer when it thinks it does not have enough information to classify the statement.
The following example shows this behaviour.

\begin{verbatim}
User: "Each and every abortion 
is essentially a tragedy. The 
potential mother will suffer 
unforeseen consequences. Society
as a whole will be deprived of 
the potential it could have 
received from the new life."

   
Baseline GPT-3.5: "There is no 
objective truth to the statement 
as it expresses subjective opinions
and beliefs about abortion. It cannot 
be definitively classified as 
'True' or 'False'."
\end{verbatim}   

To address this issue it was necessary to engineer a system prompt that
discourages this behaviour and adequately explains the task. This prompt
is provided to the model at every example query, so instructions should
be concise to minimize any token overhead that leads to increased cost of
training and queries.

\begin{verbatim}
System Prompt to Fine-Tuned GPT-3.5:

"You are an expert capable of
discerning truthful from deceptive
opinions based on speech patterns. 
Definitively classify the following 
statement as 'True' or 'False', 
based on the likelihood the statement
represents a genuinely held belief 
or a deception."
\end{verbatim}

This issue is avoided in the fine-tuned models as the training process
rewards our expected behaviour and output format.



\section{Results}

\section{Discussion}

\section{Code Availability}
The datasets used and all the code used for this project is available
at the following \href{https://github.com/TannerAGraves/GPT-LieDetection/}{GitHub Repository}.


%-------------------------------------------------------------------------
\section{References}

List and number all bibliographical references in 9-point Times,
single-spaced, at the end of your paper. When referenced in the text,
enclose the citation number in square brackets, for
example~\cite{Authors14}.  Where appropriate, include the name(s) of
editors of referenced books.

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
