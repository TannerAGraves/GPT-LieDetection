\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{Truth or DeGPTion: Evaluating Lie Detection Capabilities of GPT-3.5 through Fine-Tuning on Personal Opinions, Autobiographical Memories, and Intentions}


\author{
Tanner Graves\\
{\tt\small tanneraaron.graves@studenti.unipd.it}
\and
Marco Uderzo\\
{\tt\small marco.uderzo@studenti.unipd.it}
\and
Francesco Vo \\
{\tt\small francesco.vo@studenti.unipd.it}
\and
Mehran Faraji\\
{\tt\small mehran.faraji@studenti.unipd.it}
\and
Claudio Palmeri \\
{\tt\small claudio.palmeri@studenti.unipd.it}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
}

\maketitle
%\thispagestyle{empty}


%%%%%%%%% ABSTRACT
\begin{abstract}
This paper aims at evaluating the capabilities of GPT3.5 in the task of Lie Detection.
This is done through the fine-tuning of GPT-3.5 on three English-language datasets encompassing 
personal opinions, autobiographical memories, and future intentions. 
Fine-tuning of LLMs consists in adapting a pre-trained language model to a specific 
task by further training the model on task-specific data, thereby 
enhancing its ability to generate contextually relevant and coherent text in 
line with the desired task objectives. In our investigation, the objective is to 
discern and classify instances of truth or deception.

\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
Multiple papers consistently show that the capability of humans to discern truth from deception
is at chance level, there is a growing interest in employing Machine Learning methods, especially
based on the Transformer Model, to more accurately predict the truthfullness of a statement.
Indeed, the inherent pattern recognition capability of ML Models allows them to pick up subtle cues
that humans just seem to miss. In this paper, we will use OpenAI's GPT-3.5 Large Language Model (LLM),
performing benchmarks on the performance of the base model, and then on a GPT-3.5 model specifically
fine-tuned on the Personal Opinion Dataset (Deceptive Opinions), Autobiographical Memories Dataset (Hippocorpus) and Future Intention Dataset.

\subsection{Personal Opinion Dataset}

The participants of this study were divided in 4 groups (HIT’s) and asked to provide either 
a truthful or a deceptive opinion on the following topics: Abortion, Cannabis Legalization, Euthanasia, Gay Marriage, Policy on Migrants.
An extract from the table is shown below.

\begin{figure*}[h]
    \includegraphics[scale=0.4]{img/pers_op_dataset.jpg}
    \label{fig:personal_opinion_dataset}
\end{figure*}

\subsection{Autobiographical Memories Dataset}

This dataset contains 6854 diary-like short stories about salient life events gathered in 3 steps from 2 groups of people (A,B).
The study was conducted as following:

\begin{itemize}
    \item Stage 1: Group A writes 15-25 sentence truthful stories with a 2-3 sentence summary and a timeframe
    \item Stage 2: Group B is tasked to write an imaginative story with the summary of group A as a prompt
    \item Stage 3: After 2 months group A is asked to retell the story starting with their summary as a prompt
\end{itemize}
At the end a questionnaire was posed.

\begin{figure*}[h]
    \includegraphics[scale=0.4]{img/autobio_mem_dataset.jpg}
    \label{fig:autobiographical_memories_dataset}
\end{figure*}

\subsection{Future Intention Dataset}

The study from which this dataset was collected was conducted as following.

All participants are divided into either the truthful or deceptful group.
The former were asked to describe a non-work-related activity that would be doing in the next seven days answering the following questions:

\begin{itemize}
    \item Q1: “Please describe your activity as specific as possible”
    \item Q2: “Which information can you give us to reassure us that you are telling the truth”
\end{itemize}

The latter were given 3 activities from the former group, asked which ones didn’t apply to them and get 
randomly assigned one of those. After they were required to answer Q1, Q2 like the former group.
At the end a questionnaire was posed.

\section{Methods}

\subsection{Dataset Preprocessing}


The dataset was processed according to 'Scenario 3' of Loconte et al.\cite{Loconte}.
In Scenario 3, aggregation was performed on the three train and test sets from Scenario 1 (opinions, memories, intentions), followed by fine-tuning the model on the aggregated sets. 
This scenario evaluates the model's ability to classify truthful and deceptive statements across various contexts.

Regarding the implementation of this process, the single datasets were merged into a single one after being cleaned and shuffled. Then we divided it into training, validation and test set.
It is worth noting that we did not use all the data on the initial dataset, this is because the training of a LLM was made simpler by using a smaller training dataset.
Finally, the datasets were formatted into JSON to align with the expected input format of the OpenAI API.

In particular, the model was trained on two versions of the dataset:

\begin{itemize}
    \item a subset of the original dataset (Train: 210 examples; Validation: 45 examples; Test: 45 examples).
    \item the full dataset (Train: 6765 examples; Validation: 1450 examples; Test: 1450 examples).
\end{itemize}

\subsection{GPT-3.5 Fine-Tuning}
The model was trained utilizing the OpenAI API, and its performance was assessed through 
testing and comparison with GPT-3.5. Further experimentation was conducted to assess 
the impact of engineering the system prompt on overall performance.

Specifically, we noticed that the baseline GPT-3.5 prefers giving verbose or indecisive answers.
Verbose answers, that actually classify a statement as genuine or deceptive can be classified easily.
Nonetheless, the model decides not to give a definitive answer when it thinks it does not have enough information to classify the statement.
The following example shows this behaviour.

\begin{verbatim}
User: "Each and every abortion 
is essentially a tragedy. The 
potential mother will suffer 
unforeseen consequences. Society
as a whole will be deprived of 
the potential it could have 
received from the new life."

   
Baseline GPT-3.5: "There is no 
objective truth to the statement 
as it expresses subjective opinions
and beliefs about abortion. It cannot 
be definitively classified as 
'True' or 'False'."
\end{verbatim}   

To address this issue it was necessary to engineer a system prompt that
discourages this behaviour and adequately explains the task. This prompt
is provided to the model at every example query, so instructions should
be concise to minimize any token overhead that leads to increased cost of
training and queries.

\begin{verbatim}
System Prompt to Fine-Tuned GPT-3.5:

"You are an expert capable of
discerning truthful from deceptive
opinions based on speech patterns. 
Definitively classify the following 
statement as 'True' or 'False', 
based on the likelihood the statement
represents a genuinely held belief 
or a deception."
\end{verbatim}

This issue is avoided in the fine-tuned models as the training process
rewards our expected behaviour and output format.



\section{Results}

\section{Discussion}

\section{Code Availability}
The datasets used and all the code used for this project is available
at the following \href{https://github.com/TannerAGraves/GPT-LieDetection/}{GitHub Repository}.


%-------------------------------------------------------------------------
\section{References}

List and number all bibliographical references in 9-point Times,
single-spaced, at the end of your paper. When referenced in the text,
enclose the citation number in square brackets, for
example~\cite{Loconte}.  Where appropriate, include the name(s) of
editors of referenced books.

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}


\section{Appendix}
 
\subsection{Python Code}

\begin{verbatim}
    This should be full width, 1 column
\end{verbatim}

\end{document}
