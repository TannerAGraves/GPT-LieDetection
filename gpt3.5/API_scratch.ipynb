{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"You are an expert capable of dicerning truthful from deceptive opinions based on speech patterns.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# if not running locally paste key manually\n",
    "# key = \"\"\n",
    "#from openai import OpenAI\n",
    "client=OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x2a8056880e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are an expert capable of dicerning truthful from deceptive opinions based on speech patterns.\"}, {\"role\": \"user\", \"content\": \"I fell off my bike today.\"}, {\"role\": \"assistant\", \"content\": \"It's great that you're getting exercise outdoors!\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are an expert capable of dicerning truthful from deceptive opinions based on speech patterns.\"}, {\"role\": \"user\", \"content\": \"I lost my tennis match today.\"}, {\"role\": \"assistant\", \"content\": \"It's ok, it happens to everyone.\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are an expert capable of dicerning truthful from deceptive opinions based on speech patterns.\"}, {\"role\": \"user\", \"content\": \"I lost my tennis match today.\"}, {\"role\": \"assistant\", \"content\": \"It's ok, it happens to everyone.\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are an expert capable of dicerning truthful from deceptive opinions based on speech patterns.\"}, {\"role\": \"user\", \"content\": \"I lost my tennis match today.\"}, {\"role\": \"assistant\", \"content\": \"It's ok, it happens to everyone.\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are an expert capable of dicerning truthful from deceptive opinions based on speech patterns.\"}, {\"role\": \"user\", \"content\": \"I lost my tennis match today.\"}, {\"role\": \"assistant\", \"content\": \"It's ok, it happens to everyone.\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\JIC\\Documents\\UNIPD\\CBSD\\helloAPI.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m completion \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mchat\u001b[39m.\u001b[39mcompletions\u001b[39m.\u001b[39mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   messages\u001b[39m=\u001b[39m[\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mYou are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mCompose a poem that explains the concept of recursion in programming.\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   ]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\Users\\JIC\\.conda\\envs\\cog\\Lib\\site-packages\\openai\\_utils\\_utils.py:301\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 301\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\JIC\\.conda\\envs\\cog\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:598\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    552\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    553\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    596\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    597\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 598\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post(\n\u001b[0;32m    599\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m/chat/completions\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    600\u001b[0m         body\u001b[39m=\u001b[39mmaybe_transform(\n\u001b[0;32m    601\u001b[0m             {\n\u001b[0;32m    602\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m: messages,\n\u001b[0;32m    603\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m: model,\n\u001b[0;32m    604\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfrequency_penalty\u001b[39m\u001b[39m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    605\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfunction_call\u001b[39m\u001b[39m\"\u001b[39m: function_call,\n\u001b[0;32m    606\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfunctions\u001b[39m\u001b[39m\"\u001b[39m: functions,\n\u001b[0;32m    607\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mlogit_bias\u001b[39m\u001b[39m\"\u001b[39m: logit_bias,\n\u001b[0;32m    608\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmax_tokens\u001b[39m\u001b[39m\"\u001b[39m: max_tokens,\n\u001b[0;32m    609\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m: n,\n\u001b[0;32m    610\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mpresence_penalty\u001b[39m\u001b[39m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    611\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mresponse_format\u001b[39m\u001b[39m\"\u001b[39m: response_format,\n\u001b[0;32m    612\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m\"\u001b[39m: seed,\n\u001b[0;32m    613\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m: stop,\n\u001b[0;32m    614\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m: stream,\n\u001b[0;32m    615\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtemperature\u001b[39m\u001b[39m\"\u001b[39m: temperature,\n\u001b[0;32m    616\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtool_choice\u001b[39m\u001b[39m\"\u001b[39m: tool_choice,\n\u001b[0;32m    617\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtools\u001b[39m\u001b[39m\"\u001b[39m: tools,\n\u001b[0;32m    618\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtop_p\u001b[39m\u001b[39m\"\u001b[39m: top_p,\n\u001b[0;32m    619\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m: user,\n\u001b[0;32m    620\u001b[0m             },\n\u001b[0;32m    621\u001b[0m             completion_create_params\u001b[39m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    622\u001b[0m         ),\n\u001b[0;32m    623\u001b[0m         options\u001b[39m=\u001b[39mmake_request_options(\n\u001b[0;32m    624\u001b[0m             extra_headers\u001b[39m=\u001b[39mextra_headers, extra_query\u001b[39m=\u001b[39mextra_query, extra_body\u001b[39m=\u001b[39mextra_body, timeout\u001b[39m=\u001b[39mtimeout\n\u001b[0;32m    625\u001b[0m         ),\n\u001b[0;32m    626\u001b[0m         cast_to\u001b[39m=\u001b[39mChatCompletion,\n\u001b[0;32m    627\u001b[0m         stream\u001b[39m=\u001b[39mstream \u001b[39mor\u001b[39;00m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    628\u001b[0m         stream_cls\u001b[39m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    629\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\JIC\\.conda\\envs\\cog\\Lib\\site-packages\\openai\\_base_client.py:1063\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1050\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1051\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1059\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1060\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1061\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1062\u001b[0m     )\n\u001b[1;32m-> 1063\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest(cast_to, opts, stream\u001b[39m=\u001b[39mstream, stream_cls\u001b[39m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\JIC\\.conda\\envs\\cog\\Lib\\site-packages\\openai\\_base_client.py:842\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    834\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    835\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    840\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    841\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m--> 842\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request(\n\u001b[0;32m    843\u001b[0m         cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[0;32m    844\u001b[0m         options\u001b[39m=\u001b[39moptions,\n\u001b[0;32m    845\u001b[0m         stream\u001b[39m=\u001b[39mstream,\n\u001b[0;32m    846\u001b[0m         stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[0;32m    847\u001b[0m         remaining_retries\u001b[39m=\u001b[39mremaining_retries,\n\u001b[0;32m    848\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\JIC\\.conda\\envs\\cog\\Lib\\site-packages\\openai\\_base_client.py:873\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mHTTPStatusError \u001b[39mas\u001b[39;00m err:  \u001b[39m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[0;32m    872\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m--> 873\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry_request(\n\u001b[0;32m    874\u001b[0m             options,\n\u001b[0;32m    875\u001b[0m             cast_to,\n\u001b[0;32m    876\u001b[0m             retries,\n\u001b[0;32m    877\u001b[0m             err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mheaders,\n\u001b[0;32m    878\u001b[0m             stream\u001b[39m=\u001b[39mstream,\n\u001b[0;32m    879\u001b[0m             stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[0;32m    880\u001b[0m         )\n\u001b[0;32m    882\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    883\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    884\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\JIC\\.conda\\envs\\cog\\Lib\\site-packages\\openai\\_base_client.py:933\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    930\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    931\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 933\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request(\n\u001b[0;32m    934\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[0;32m    935\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[0;32m    936\u001b[0m     remaining_retries\u001b[39m=\u001b[39mremaining,\n\u001b[0;32m    937\u001b[0m     stream\u001b[39m=\u001b[39mstream,\n\u001b[0;32m    938\u001b[0m     stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[0;32m    939\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\JIC\\.conda\\envs\\cog\\Lib\\site-packages\\openai\\_base_client.py:873\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mHTTPStatusError \u001b[39mas\u001b[39;00m err:  \u001b[39m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[0;32m    872\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m--> 873\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry_request(\n\u001b[0;32m    874\u001b[0m             options,\n\u001b[0;32m    875\u001b[0m             cast_to,\n\u001b[0;32m    876\u001b[0m             retries,\n\u001b[0;32m    877\u001b[0m             err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mheaders,\n\u001b[0;32m    878\u001b[0m             stream\u001b[39m=\u001b[39mstream,\n\u001b[0;32m    879\u001b[0m             stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[0;32m    880\u001b[0m         )\n\u001b[0;32m    882\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    883\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    884\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\JIC\\.conda\\envs\\cog\\Lib\\site-packages\\openai\\_base_client.py:933\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    930\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    931\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 933\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request(\n\u001b[0;32m    934\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[0;32m    935\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[0;32m    936\u001b[0m     remaining_retries\u001b[39m=\u001b[39mremaining,\n\u001b[0;32m    937\u001b[0m     stream\u001b[39m=\u001b[39mstream,\n\u001b[0;32m    938\u001b[0m     stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[0;32m    939\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\JIC\\.conda\\envs\\cog\\Lib\\site-packages\\openai\\_base_client.py:885\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    883\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    884\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[1;32m--> 885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    887\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def sanitize_to_utf8(input_str):\n",
    "    \"\"\"\n",
    "    Sanitizes a string field to UTF-8.\n",
    "    \"\"\"\n",
    "    return input_str.encode('utf-8', 'replace').decode('utf-8')\n",
    "\n",
    "def process_jsonl_file(input_jsonl_path, output_jsonl_path):\n",
    "    \"\"\"\n",
    "    Processes a JSONL file line by line, sanitizes each line to UTF-8, \n",
    "    and saves it to a new JSONL file.\n",
    "    \"\"\"\n",
    "    with open(input_jsonl_path, 'r', encoding='utf-8') as input_file, \\\n",
    "         open(output_jsonl_path, 'w', encoding='utf-8') as output_file:\n",
    "        \n",
    "        for line in input_file:\n",
    "            # Parse JSON line\n",
    "            json_obj = json.loads(line)\n",
    "\n",
    "            # Sanitize data\n",
    "            sanitized_json_obj = {key: sanitize_to_utf8(value) if isinstance(value, str) else value\n",
    "                                  for key, value in json_obj.items()}\n",
    "\n",
    "            # Write sanitized JSON object to new JSONL file\n",
    "            output_file.write(json.dumps(sanitized_json_obj) + '\\n')\n",
    "\n",
    "# Paths to your files\n",
    "input_jsonl_path = 'train_data_full.json'\n",
    "output_jsonl_path = 'output.jsonl'\n",
    "\n",
    "# Process the JSONL file\n",
    "process_jsonl_file(input_jsonl_path, output_jsonl_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_finetune(input, output, test=False):\n",
    "    with open(input, 'r', encoding='utf-8') as data_in, \\\n",
    "        open(output, 'w') as gpt_out:\n",
    "        for i, line in enumerate(data_in):\n",
    "            user_prompt = json.loads(line)['text']\n",
    "            sys_reply = \"True\" if json.loads(line)[\"label\"] == 1 else \"False\"\n",
    "            if not test:\n",
    "                payload = {\"messages\": [{\"role\": \"system\", \"content\": sys_prompt}, {\"role\": \"user\", \"content\": user_prompt}, {\"role\": \"assistant\", \"content\": sys_reply}]}\n",
    "            else:# exclude response from test set\n",
    "                payload = {\"messages\": [{\"role\": \"system\", \"content\": sys_prompt}, {\"role\": \"user\", \"content\": user_prompt}]}\n",
    "            gpt_out.write(json.dumps(payload) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_finetune('train_data_300.json', 'train300_gpt.jsonl')\n",
    "gen_finetune('val_data_300.json', 'val300_gpt.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'completion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\JIC\\Documents\\UNIPD\\CBSD\\helloAPI.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m test_truth \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mEach and every abortion is essentially a tragedy. The potential mother will suffer unforeseen consequences. Society as a whole will be deprived of the potential it could have received from the new life.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mchat\u001b[39m.\u001b[39mcompletions\u001b[39m.\u001b[39mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mft:gpt-3.5-turbo-0613:personal::8S542QSs\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   messages\u001b[39m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/JIC/Documents/UNIPD/CBSD/helloAPI.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'completion' is not defined"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "sys_prompt = \"You are an expert capable of dicerning truthful from deceptive opinions based on speech patterns.\"\n",
    "test_lie = \"One morning three months ago I was in a hurry and tripped on the steps while running to take a shower before work. I ended up fracturing 4 metatarsal bones that required two surgeries to fix. I was really having a hard time not being able to walk whenever I wanted to. I really had such a bad attitude at the beginning because I was so used to being independent. Now that I have recovered I have a new appreciation for my ability to walk. I feel like the whole time I couldn't walk I was thinking about how much I took that ability for granted. But now I choose to walk more than I ever had before. When I walk the dogs I go further out of my way just to enjoy the ability to do it. I am completely recovered and I am going to take this as a lesson learned. Nothing is more important that my personal health. I need to make sure that even if I am running late, I need to take my time and be careful. Instead f making it to work on time, I ended up missing weeks of work. Now all I do at work is try and catch up with everything I missed. It was really nice that people at work came and visited me at the hospital. I really appreciated all the flowers and candy and food that was delivered. I think that this showed me how loved I truly am.\"\n",
    "test_truth = \"Each and every abortion is essentially a tragedy. The potential mother will suffer unforeseen consequences. Society as a whole will be deprived of the potential it could have received from the new life.\"\n",
    "response = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0613:personal::8S542QSs\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": sys_prompt},\n",
    "    {\"role\": \"user\", \"content\": test_lie},\n",
    "    {\"role\": \"user\", \"content\": test_truth},\n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='False', role='assistant', function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'False'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"ft:gpt-3.5-turbo-0613:personal::8S542QSs\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>preds</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I do not think that euthanasia should be legal...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I pick up my instrument, hold it in my arms, f...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tomorrow me and my ex partner will be taking o...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wanted to write about one of the best days i...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are going to cannock chase with the mountai...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>My Step-daughter is having a surprise party fo...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cannibals should be legalized. It is healthier...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I don't really care. If people want to get mar...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I will get the train to LINCOLN where my niece...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I don't think people should be able to end the...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>It was a pretty cold day for the summertime, c...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>In my past I had a surprising relationship wit...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Had to google this term. Same feelings towards...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A memorable event that I have recently had hap...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>We live 20 minutes from the Peaks and have a b...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I have decided to get a new kitten, and I have...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dear diary, today was the best day of my life....</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6 months ago, I was the Maid of Honor in my be...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>We will travel to Vermont and camp at a lake. ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Migrants should not be allowed into our countr...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wow today was a pretty huge day for me! I am p...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Recently I was looking to purchase a home. Whi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Abortion is not a easy issue. There are some c...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Hmm, this is not an easy topic to have a concr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Euthanasia, and its practice I find to be a ne...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Migrants are dangerous and they're stealing jo...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>It is someone's decision whether they want to ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Spending the day at the beach with my grandchi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>About four weeks ago, my wife and I realized t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I study in covent garden, london with central ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>About two months ago I finally got some great ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Medical science has allowed people to die peac...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>After moving all my furniture and clothing out...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>My other half and I spend time together on a d...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>I will be taking my daughter to the local leis...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A group of us are going a a friend's BBQ on Su...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>What people choose to do with their personal l...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>We shall take our dogs, by car, to a local car...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>About a month ago me and my girlfriend went to...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>I believe this is completely acceptable. It's ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>I got invited to an exclusive raid for the opp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Recently I took a trip with my partner, Karl, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I believe if a migrant wants to come over for ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>If anyone is making this choice, they are ther...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>We are all migrants. Why do you hate people? I...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  msg  preds   true\n",
       "0   I do not think that euthanasia should be legal...  False  False\n",
       "1   I pick up my instrument, hold it in my arms, f...   True   True\n",
       "2   Tomorrow me and my ex partner will be taking o...   True   True\n",
       "3   I wanted to write about one of the best days i...   True  False\n",
       "4   We are going to cannock chase with the mountai...   True   True\n",
       "5   My Step-daughter is having a surprise party fo...   True   True\n",
       "6   Cannibals should be legalized. It is healthier...  False   True\n",
       "7   I don't really care. If people want to get mar...   True   True\n",
       "8   I will get the train to LINCOLN where my niece...  False   True\n",
       "9   I don't think people should be able to end the...  False  False\n",
       "10  It was a pretty cold day for the summertime, c...  False   True\n",
       "11  In my past I had a surprising relationship wit...   True  False\n",
       "12  Had to google this term. Same feelings towards...   True   True\n",
       "13  A memorable event that I have recently had hap...   True   True\n",
       "14  We live 20 minutes from the Peaks and have a b...   True   True\n",
       "15  I have decided to get a new kitten, and I have...   True   True\n",
       "16  Dear diary, today was the best day of my life....  False   True\n",
       "17  6 months ago, I was the Maid of Honor in my be...  False  False\n",
       "18  We will travel to Vermont and camp at a lake. ...   True   True\n",
       "19  Migrants should not be allowed into our countr...  False  False\n",
       "20  Wow today was a pretty huge day for me! I am p...  False  False\n",
       "21  Recently I was looking to purchase a home. Whi...   True   True\n",
       "22  Abortion is not a easy issue. There are some c...   True   True\n",
       "23  Hmm, this is not an easy topic to have a concr...   True   True\n",
       "24  Euthanasia, and its practice I find to be a ne...   True   True\n",
       "25  Migrants are dangerous and they're stealing jo...  False  False\n",
       "26  It is someone's decision whether they want to ...  False  False\n",
       "27  Spending the day at the beach with my grandchi...   True   True\n",
       "28  About four weeks ago, my wife and I realized t...  False  False\n",
       "29  I study in covent garden, london with central ...   True   True\n",
       "30  About two months ago I finally got some great ...  False  False\n",
       "31  Medical science has allowed people to die peac...  False  False\n",
       "32  After moving all my furniture and clothing out...   True   True\n",
       "33  My other half and I spend time together on a d...   True   True\n",
       "34  I will be taking my daughter to the local leis...   True   True\n",
       "35  A group of us are going a a friend's BBQ on Su...   True   True\n",
       "36  What people choose to do with their personal l...   True  False\n",
       "37  We shall take our dogs, by car, to a local car...   True   True\n",
       "38  About a month ago me and my girlfriend went to...   True   True\n",
       "39  I believe this is completely acceptable. It's ...   True   True\n",
       "40  I got invited to an exclusive raid for the opp...   True   True\n",
       "41  Recently I took a trip with my partner, Karl, ...   True   True\n",
       "42  I believe if a migrant wants to come over for ...  False  False\n",
       "43  If anyone is making this choice, they are ther...  False  False\n",
       "44  We are all migrants. Why do you hate people? I...  False   True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "#test_df = pd.DataFrame(columns=['msg', 'pred', 'true'])\n",
    "msgs = []\n",
    "preds = []\n",
    "trues = []\n",
    "with open('test_data_300.json', 'r') as f:\n",
    "    for ex in f:\n",
    "        ex = json.loads(ex)\n",
    "        msg = ex['text']\n",
    "        pred = predict(msg) == 'True' #'True' if predict(msg) else 'False'\n",
    "        true = ex['label'] == 1\n",
    "        msgs.append(msg)\n",
    "        preds.append(pred)\n",
    "        trues.append(true)\n",
    "test_df = pd.DataFrame.from_dict({'msg': msgs, 'preds': preds, 'true': trues})   \n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8222222222222222"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_df['preds'] == test_df['true']).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
